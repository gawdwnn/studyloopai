// Sample cuecard data for development and testing
// In production, this would be replaced with data from the database

export const SAMPLE_CUECARDS = [
	{
		id: "1",
		keyword: "LLM (Large Language Model)",
		definition:
			"These advanced neural models are trained on vast amounts of text data to understand context, generate detailed responses, and support nuanced reasoning. They empower systems to dynamically manage and execute complex workflows by selecting appropriate tools and adapting decisions as needed.",
		source: "Week 2 - Practical-guide-to-building-LLMs.pdf",
	},
	{
		id: "2",
		keyword: "Transformer Architecture",
		definition:
			"A neural network architecture that uses self-attention mechanisms to process sequences of data, enabling parallel processing and better handling of long-range dependencies compared to RNNs.",
		source: "Week 2 - Practical-guide-to-building-LLMs.pdf",
	},
	{
		id: "3",
		keyword: "Attention Mechanism",
		definition:
			"A technique that allows neural networks to focus on relevant parts of input data when making predictions, improving performance on tasks requiring understanding of context and relationships.",
		source: "Week 1 - Neural Networks Fundamentals.pdf",
	},
	{
		id: "4",
		keyword: "Fine-tuning",
		definition:
			"The process of adapting a pre-trained model to a specific task by continuing training on task-specific data, allowing the model to specialize while retaining general knowledge.",
		source: "Week 3 - Advanced AI Architectures.pdf",
	},
	{
		id: "5",
		keyword: "Embeddings",
		definition:
			"Dense vector representations of words, phrases, or other data that capture semantic meaning and relationships in a continuous vector space.",
		source: "Week 2 - Practical-guide-to-building-LLMs.pdf",
	},
	{
		id: "6",
		keyword: "Tokenization",
		definition:
			"The process of converting text into smaller units (tokens) that can be processed by machine learning models, such as words, subwords, or characters.",
		source: "Week 1 - Neural Networks Fundamentals.pdf",
	},
	{
		id: "7",
		keyword: "Backpropagation",
		definition:
			"An algorithm used to train neural networks by calculating gradients of the loss function with respect to network weights and propagating them backward through the network.",
		source: "Week 1 - Neural Networks Fundamentals.pdf",
	},
	{
		id: "8",
		keyword: "Gradient Descent",
		definition:
			"An optimization algorithm that iteratively adjusts model parameters in the direction of steepest descent of the loss function to minimize prediction errors.",
		source: "Week 1 - Neural Networks Fundamentals.pdf",
	},
];
